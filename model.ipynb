{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.device('/gpu:0') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\X.npy')\n",
    "y = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = MinMaxScaler()\n",
    "X = X.reshape(-1,1)\n",
    "X = Scaler.fit_transform(X)\n",
    "X = X.reshape(304,1000,10,6)\n",
    "y = y.reshape(-1,1)\n",
    "y = Scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle, y_shuffle = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = X_shuffle[:300,:,:,:], y_shuffle[:300]\n",
    "test_X, test_y = X_shuffle[300:, :, :, :], y_shuffle[300:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32,(3,3), activation='relu',padding='same', input_shape=(1000,10,6)))\n",
    "model_1.add(layers.MaxPooling2D((2,2)))\n",
    "model_1.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2,2)))\n",
    "model_1.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "#model_1.add(layers.Lambda(lambda x: keras.backend.expand_dims(x, axis=-1)))\n",
    "#model_1.add(layers.LSTM(units=128, return_sequences=True))\n",
    "model_1.add(layers.Dense(128,activation='relu'))\n",
    "model_1.add(layers.Dense(64,activation='relu'))\n",
    "model_1.add(layers.Dense(1,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "               loss='mse',\n",
    "               metrics=['mae']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_mae', patience=50, verbose=2)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_mae', patience=10, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\model\\\\full_cnn.h5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "callback = [early_stopping, learning_rate_reduction, checkpoint]\n",
    "history = model_1.fit(train_X, train_y, epochs=1000, validation_data=(test_X, test_y), batch_size=10,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='训练集loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='验证集loss', linewidth=2)\n",
    "plt.xlabel('训练轮次')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='-.')\n",
    "plt.savefig('E:\\\\毕业设计\\\\毕业\\\\V0\\\\figs\\\\第五章\\\\loss训练过程.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'], label='训练集mae', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='验证集mae', linewidth=2)\n",
    "plt.xlabel('训练轮次')\n",
    "plt.ylabel('MAE/Ah')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='-.')\n",
    "plt.savefig('E:\\\\毕业设计\\\\毕业\\\\V0\\\\figs\\\\第五章\\\\mae训练过程.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Scaler.inverse_transform(res))\n",
    "plt.plot(Scaler.inverse_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Scaler.inverse_transform(res)\n",
    "res = pd.DataFrame(res)\n",
    "res.to_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\容量预测结果_全CNN模型.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\model\\\\full_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax预测概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\X.npy')\n",
    "y = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = MinMaxScaler()\n",
    "X = X.reshape(-1,1)\n",
    "X = Scaler.fit_transform(X)\n",
    "X = X.reshape(304,1000,10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(304):\n",
    "    if i < 100:\n",
    "        y[i] = 0\n",
    "    elif i < 230:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(64,(3,3), activation='relu',padding='same', input_shape=(1000,10,6)))\n",
    "model_1.add(layers.MaxPooling2D((2,2)))\n",
    "model_1.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2,2)))\n",
    "model_1.add(layers.Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "#model_1.add(layers.Lambda(lambda x: keras.backend.expand_dims(x, axis=-1)))\n",
    "#model_1.add(layers.LSTM(units=128, return_sequences=True))\n",
    "model_1.add(layers.Dense(128,activation='relu'))\n",
    "model_1.add(layers.Dense(64,activation='relu'))\n",
    "model_1.add(layers.Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X,y,epochs=50,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(res)\n",
    "temp.iloc[:,0] = state_1\n",
    "temp.iloc[:,1] = state_2\n",
    "temp.iloc[:,2] = state_3\n",
    "temp.to_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\状态概率预测.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(res)\n",
    "temp.iloc[:,0] = state_1\n",
    "temp.iloc[:,1] = state_2\n",
    "temp.iloc[:,2] = state_3\n",
    "temp.to_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\系统状态概率预测.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+LSTM混合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混合模型需要训练好长时间才能效果好，至少要几百个轮次，需要配置GPU或用云跑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import concatenate, LSTM, Conv1D, Conv2D, Flatten, TimeDistributed, Input, Dense, MaxPooling1D, MaxPooling2D, Dropout, Activation\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\X.npy')\n",
    "y = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = MinMaxScaler()\n",
    "X = X.reshape(-1,1)\n",
    "X = Scaler.fit_transform(X)\n",
    "X = X.reshape(304,1000,10,6)\n",
    "y = y.reshape(-1,1)\n",
    "y = Scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle, y_shuffle = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = X_shuffle[:263,:,:,:], y_shuffle[:263]\n",
    "test_X, test_y = X_shuffle[263:, :, :, :], y_shuffle[263:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.expand_dims(X, axis=-1)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(Conv1D(64,9, activation='relu',padding='same', input_shape=(1000,10,6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(MaxPooling1D()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(Conv1D(128,9, activation='relu',padding='same')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(MaxPooling1D()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(Conv1D(128,9, activation='relu',padding='same')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(TimeDistributed(Flatten())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(Dropout(0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(LSTM(units=128, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(LSTM(units=50, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(128,activation='relu'))\n",
    "#model_2.add(Dense(64,activation='relu'))\n",
    "model_2.add(Dense(1,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "               loss='mse',\n",
    "               metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_mae', patience=50, verbose=2)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_mae', patience=10, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\model\\\\cnn+lstm.h5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "callback = [early_stopping, learning_rate_reduction, checkpoint]\n",
    "history = model_2.fit(train_X, train_y, epochs=1000, validation_data=(test_X, test_y), batch_size=10,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Scaler.inverse_transform(res))\n",
    "plt.plot(Scaler.inverse_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Scaler.inverse_transform(res))\n",
    "plt.plot(Scaler.inverse_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Scaler.inverse_transform(res)\n",
    "res = pd.DataFrame(res)\n",
    "res.to_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\容量预测结果_混合模型.csv',index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\model\\\\cnn+lstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+LSTM+BNN混合模型（得上云跑了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import concatenate, LSTM, Conv1D, Conv2D, Flatten, TimeDistributed, Input, Dense, MaxPooling1D, MaxPooling2D, Dropout, Activation, Reshape\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\X.npy')\n",
    "y = np.load('E:\\\\毕业设计\\\\毕业\\\\V0\\\\data\\\\data_processed\\\\y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = MinMaxScaler()\n",
    "X = X.reshape(-1,1)\n",
    "X = Scaler.fit_transform(X)\n",
    "X = X.reshape(304,1000,10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)\n",
    "for i in range(304):\n",
    "    if i <= 80:\n",
    "        y[i][0] = 1\n",
    "    elif i <= 150:\n",
    "        y[i][0] = 2\n",
    "    else:\n",
    "        y[i][0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle, y_shuffle = shuffle(X, y)\n",
    "train_X, train_y = X_shuffle[:263,:,:,:], y_shuffle[:263]\n",
    "test_X, test_y = X_shuffle[263:, :, :, :], y_shuffle[263:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义BNN层（这一部分若使用GPU训练会存在许多的版本问题，使用CPU问题少一点）\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.compat.v1.keras import activations, initializers\n",
    "from tensorflow.compat.v1.keras.layers import Layer\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras.layers import Input\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras import *\n",
    "\n",
    "def mixture_prior_params(sigma_1, sigma_2, pi, return_sigma=False):\n",
    "    params = K.variable([sigma_1, sigma_2, pi], name='mixture_prior_params')\n",
    "    sigma = np.sqrt(pi * sigma_1 ** 2 + (1 - pi) * sigma_2 ** 2)\n",
    "    return params, sigma\n",
    " \n",
    "def log_mixture_prior_prob(w):\n",
    "    comp_1_dist = tf.distributions.Normal(0.0, prior_params[0])\n",
    "    comp_2_dist = tf.distributions.Normal(0.0, prior_params[1])\n",
    "    comp_1_weight = prior_params[2]    \n",
    "    return K.log(comp_1_weight * comp_1_dist.prob(w) + (1 - comp_1_weight) * comp_2_dist.prob(w))    \n",
    " \n",
    "# Mixture prior parameters shared across DenseVariational layer instances\n",
    "prior_params, prior_sigma = mixture_prior_params(sigma_1=1.0, sigma_2=0.1, pi=0.2)\n",
    " \n",
    "class DenseVariational(Layer):\n",
    "    def __init__(self, output_dim, kl_loss_weight, activation=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kl_loss_weight = kl_loss_weight\n",
    "        self.activation = activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):  \n",
    "        self._trainable_weights.append(prior_params) \n",
    " \n",
    "        self.kernel_mu = self.add_weight(name='kernel_mu', \n",
    "                                         shape=(input_shape[1], self.output_dim),\n",
    "                                         initializer=initializers.normal(stddev=prior_sigma),\n",
    "                                         trainable=True)\n",
    "        self.bias_mu = self.add_weight(name='bias_mu', \n",
    "                                       shape=(self.output_dim,),\n",
    "                                       initializer=initializers.normal(stddev=prior_sigma),\n",
    "                                       trainable=True)\n",
    "        self.kernel_rho = self.add_weight(name='kernel_rho', \n",
    "                                          shape=(input_shape[1], self.output_dim),\n",
    "                                          initializer=initializers.constant(0.0),\n",
    "                                          trainable=True)\n",
    "        self.bias_rho = self.add_weight(name='bias_rho', \n",
    "                                        shape=(self.output_dim,),\n",
    "                                        initializer=initializers.constant(0.0),\n",
    "                                        trainable=True)\n",
    "        super().build(input_shape)\n",
    " \n",
    "    def call(self, x):\n",
    "        kernel_sigma = tf.math.softplus(self.kernel_rho)\n",
    "        kernel = self.kernel_mu + kernel_sigma * tf.random.normal(self.kernel_mu.shape)\n",
    " \n",
    "        bias_sigma = tf.math.softplus(self.bias_rho)\n",
    "        bias = self.bias_mu + bias_sigma * tf.random.normal(self.bias_mu.shape)\n",
    "                \n",
    "        self.add_loss(self.kl_loss(kernel, self.kernel_mu, kernel_sigma) + \n",
    "                      self.kl_loss(bias, self.bias_mu, bias_sigma))\n",
    "        \n",
    "        return self.activation(K.dot(x, kernel) + bias)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    def kl_loss(self, w, mu, sigma):\n",
    "        variational_dist = tf.distributions.Normal(mu, sigma)\n",
    "        return kl_loss_weight * K.sum(variational_dist.log_prob(w) - log_mixture_prior_prob(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_X.shape[0]\n",
    "batch_size = 5\n",
    "num_batches = train_size / batch_size\n",
    "kl_loss_weight = 1.0 / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN+LSTM\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(TimeDistributed(Conv1D(64,9, activation='relu',padding='same', input_shape=(1000,10,6))))\n",
    "model_2.add(TimeDistributed(MaxPooling1D()))\n",
    "model_2.add(TimeDistributed(Conv1D(128,9, activation='relu',padding='same')))\n",
    "model_2.add(TimeDistributed(MaxPooling1D()))\n",
    "model_2.add(TimeDistributed(Conv1D(128,9, activation='relu',padding='same')))\n",
    "model_2.add(TimeDistributed(Flatten())) \n",
    "model_2.add(Dropout(0.5)) \n",
    "model_2.add(LSTM(units=128, return_sequences=True))\n",
    "model_2.add(LSTM(units=50, return_sequences=True))\n",
    "model_2.add(Reshape((50,1000,-1)))\n",
    "# BNN\n",
    "model_2.add(DenseVariational(50, kl_loss_weight=kl_loss_weight, activation='relu'))\n",
    "model_2.add(DenseVariational(20, kl_loss_weight=kl_loss_weight, activation='relu'))\n",
    "model_2.add(Reshape((50,3,-1)))\n",
    "model_2.add(DenseVariational(3, kl_loss_weight=kl_loss_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(y_obs, y_pred, sigma=1.0):\n",
    "    dist = tf.distributions.Normal(loc=y_pred, scale=sigma)\n",
    "    return K.sum(-dist.log_prob(y_obs))\n",
    " \n",
    "model_2.compile(loss=neg_log_likelihood, optimizer=optimizers.Adam(lr=0.001), metrics=['mse'])\n",
    "model_2.fit(train_X, train_y, batch_size=batch_size, epochs=1500, verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯网络推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import pandas as pd\n",
    "from pgmpy.inference import VariableElimination\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_model = BayesianModel([('Cell_3', 'Road_2'), \n",
    "                              ('Cell_4', 'Road_2'),\n",
    "                              ('Road_1', 'Battery_Pack'),\n",
    "                              ('Road_2', 'Battery_Pack')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBN(model,save=False):\n",
    "    '''传入BayesianModel对象，调用graphviz绘制结构图，jupyter中可直接显示'''\n",
    "    node_attr = dict(\n",
    "     style='filled',\n",
    "     shape='box',\n",
    "     align='left',\n",
    "     fontsize='12',\n",
    "     ranksep='0.1',\n",
    "     height='0.2'\n",
    "    )\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    edges=model.edges()\n",
    "    for a,b in edges:\n",
    "        dot.edge(a,b)\n",
    "    if save:\n",
    "        dot.view(cleanup=True)\n",
    "    return dot\n",
    "showBN(battery_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = BayesianModel([('Cell_3', 'Road_2'), ('Cell_4', 'Road_2')])\n",
    "#model = BayesianModel([('A', 'C'), ('B', 'C')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\data\\\\电池组状态数据.csv')\n",
    "#data = pd.DataFrame(data={'A': [0, 0, 1], 'B': [0, 1, 0], 'C': [1, 1, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BayesianEstimator(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_C = estimator.estimate_cpd('Road_2')#, prior_type=\"dirichlet\", pseudo_counts=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpd_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_cell3 = TabularCPD(variable='Cell_3', variable_card=3,\n",
    "                      values=[[0.6], [0.2], [0.2]])\n",
    "cpd_cell4 = TabularCPD(variable='Cell_4', variable_card=3,\n",
    "                       values=[[0.6], [0.2], [0.2]])\n",
    "cpd_road1 = TabularCPD(variable='Road_1', variable_card=3,\n",
    "                       values=[[0.9],[0.0],[0.1]])\n",
    "cpd_road2 = TabularCPD(variable='Road_2', variable_card=3,\n",
    "                        values=[[0.98, 0.3, 0.2, 0.3, 0.0037, 0.0333, 0.1, 0.0208, 0.0088],\n",
    "                                [0.01, 0.6, 0.4, 0.6, 0.9370, 0.9333, 0.6, 0.3333, 0.1193],\n",
    "                                [0.01, 0.1, 0.4, 0.1, 0.0593, 0.0333, 0.3, 0.6458, 0.8719]],\n",
    "                        evidence=['Cell_3', 'Cell_4'],\n",
    "                        evidence_card=[3,3])\n",
    "cpd_pack = TabularCPD(variable='Battery_Pack', variable_card=3,\n",
    "                      values=[[0.9188, 0.6465, 0.3333, 0.3333, 0.0037, 0.0333, 0.3333, 0.0208, 0.0088],\n",
    "                              [0.0784, 0.3434, 0.3333, 0.3333, 0.9370, 0.9333, 0.3333, 0.3333, 0.0193],\n",
    "                              [0.0028, 0.0101, 0.3333, 0.3333, 0.0593, 0.0333, 0.3333, 0.6458, 0.9719]],\n",
    "                      evidence=['Road_1', 'Road_2'], evidence_card=[3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_model.add_cpds(cpd_cell3, cpd_cell4, cpd_road1, cpd_road2, cpd_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_model.get_independencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_infer = VariableElimination(battery_model)\n",
    "q = model_infer.query(variables=['Road_2'], evidence={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\\\毕业设计\\\\毕业\\\\V0\\data\\\\电池组状态数据.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = data.drop(columns=['Battery_Pack'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = battery_model.predict(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred['Battery_Pack'] == data['Battery_Pack']).sum()/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
